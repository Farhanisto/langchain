{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Chaining\n",
    "\n",
    "## 1. Extendend or sequential chaining\n",
    "chaining tasks one by one in a sequential line\n",
    "\n",
    "## 2. parallel chaining\n",
    "lets you run tasks without depending on other tasks \n",
    "\n",
    "## 3. conditional chaining\n",
    "lets you run a particular branch based on a condition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Turing Test is a method of inquiry in artificial intelligence (AI) for determining whether or not a computer is capable of human-like intelligence. Proposed by the British mathematician and computer scientist Alan Turing in 1950, the test involves a human evaluator who carries out natural language conversations with another human and a machine designed to generate human-like responses. The evaluator knows that one of the two partners in conversation is a machine, and all participants are separated from one another. If the evaluator cannot reliably tell the machine from the human, the machine is said to have passed the test. The test does not check the ability to give correct answers, it checks how closely the answer resembles typical human answers.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def main():\n",
    "    # Initialize the language model\n",
    "    llm = ChatOpenAI(model=\"gpt-4\", temperature=0.0)\n",
    "\n",
    "    # Define the prompt template\n",
    "    # prompt = PromptTemplate(\n",
    "    #     input_variables=[\"question\"],\n",
    "    #     template=\"Answer the question: {question}\",\n",
    "    # )\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful assistant in the {field}.\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ])\n",
    "\n",
    "    # Create the output parser\n",
    "    output_parser = StrOutputParser()\n",
    "\n",
    "    # Combine the components into a single chain\n",
    "    chain = prompt | llm | output_parser\n",
    "\n",
    "    # Run the chain with a sample question\n",
    "    result = chain.invoke({\"field\": \"computer science\", \"question\": \"What is the Turing test?\"})\n",
    "    \n",
    "    print(result)\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "# This script uses LangChain to create a simple question-answering chain with OpenAI's GPT-4 model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUNNABLES:- To provide extra processing, this are the inner workings of the pipe operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Turing Test is a method of inquiry in artificial intelligence (AI) for determining whether or not a computer is capable of human-like intelligence. It was proposed by the British mathematician and computer scientist Alan Turing in 1950.\n",
      "\n",
      "In the test, a human evaluator interacts with a computer program and a human through a computer interface. If the evaluator cannot reliably tell the program from the human, the machine is said to have passed the test and demonstrated human-like intelligence.\n",
      "\n",
      "However, it's important to note that passing the Turing Test doesn't necessarily mean the machine has the same consciousness or understanding as a human. It simply means it was able to produce responses that were indistinguishable from those of a human in that specific context.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableLambda, RunnableSequence\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "def main(): \n",
    "    # Initialize the language model\n",
    "    llm = ChatOpenAI(model=\"gpt-4\", temperature=0.0)\n",
    "\n",
    "    # Define the prompt template\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful assistant in the {field}.\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ])\n",
    "\n",
    "    # Create a simple chain using RunnableSequence\n",
    "    chain = RunnableSequence(\n",
    "        prompt,\n",
    "        llm,\n",
    "        RunnableLambda(lambda x: x.content)\n",
    "    )\n",
    "\n",
    "    # Run the chain with a sample question\n",
    "    result = chain.invoke({\"field\": \"computer science\", \"question\": \"What is the Turing test?\"})\n",
    "    \n",
    "    print(result)\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "# This script uses LangChain to create a simple question-answering chain with OpenAI's GPT-4 model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Kombiyuutarka elektroniga ee ugu horeeyay ee ENIAC wuxuu miisaaniyadda ka badnaa 27 oo tan, wuxuuna ka dhacayaa 1800 fut koonfur. Waxaa soo saaray Ciidamada Mareykanka ee Dagaalkii Adduunka ee Labaad, waxaana loogu adeegsaday in lagu xisaabiyo miisaska dagaalka.\n",
      "\n",
      "2. Qofka ugu horeysay ee barnaamijka kombiyuutarka waxay ahayd haweeney lagu magacaabo Ada Lovelace. Waxay ka shaqaysay kombiyuutarka guud ee hore ee farsamo ee Charles Babbage, oo loo yaqaanay Injineerka Farsamo, waxayna qortay xeerka mashiinka ee ugu horeeya ee adduunka ee loogu talagalay mashiin farsamo oo kaliya ku jirta warqad.\n",
      "\n",
      "3. Fayraska kombiyuutarka ugu horeeyay waxaa sameeyay 1971-kii Robert Thomas, injineer ka tirsan shirkadda BBN Technologies. Lagu magacaabay \"Creeper\", wuxuu ahaa barnaamij is-dupliki ah oo tijaabo ah oo aan ahayn mid waxyeelo leh, laakiin waxaa loo sameeyay in lagu muujiyo barnaamijka gacanta.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda, RunnableSequence\n",
    "load_dotenv()   \n",
    "\n",
    "def main():\n",
    "    # Initialize the language model\n",
    "    llm = ChatOpenAI(model=\"gpt-4\", temperature=0.0)\n",
    "\n",
    "    # Define the prompt template\n",
    "    prompt_facts = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You like telling facts about {field}.\"),\n",
    "        (\"human\", \"Tell me {count} facts.\"),\n",
    "    ])\n",
    "\n",
    "    prompt_traslations = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful translator.\"),\n",
    "        (\"human\", \"Translate '{text}' to {language}.\"),\n",
    "    ])\n",
    "\n",
    "    count_words = RunnableLambda(lambda x: len(x.split()))\n",
    "    prepare_for_translation = RunnableLambda(lambda x: {\n",
    "        \"text\": x,\n",
    "        \"language\": \"Somali\"\n",
    "    })\n",
    "\n",
    "    # Create a chain for facts\n",
    "    # facts_chain = RunnableSequence(\n",
    "    #     prompt_facts,\n",
    "    #     llm,\n",
    "    #     StrOutputParser()\n",
    "    # )\n",
    "    # # Create a chain for translations\n",
    "    # chain = RunnableSequence(\n",
    "    #     facts_chain,\n",
    "    #     count_words,\n",
    "    #     prepare_for_translation,\n",
    "    #     prompt_traslations,\n",
    "    #     llm,\n",
    "    #     StrOutputParser()\n",
    "    # )\n",
    "\n",
    "    chain = prompt_facts | llm | StrOutputParser() | prepare_for_translation | prompt_traslations | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "    # Run the chain with a sample question\n",
    "    result = chain.invoke({\"field\": \"computer science\", \"count\": \"3\"})\n",
    "    \n",
    "    print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Chaining: Write a blog post to analyze the movie inception. Chain 1 analyzes the plot chain 2 analyzes the charater\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot Verdict: \"Inception\" is a masterclass in storytelling, with its strongest points being its intricate plot, compelling characters, and innovative exploration of the subconscious mind. The film's complex narrative structure, which involves multiple layers of dreams within dreams, is a testament to Christopher Nolan's genius as a writer and director. The plot is not only intellectually stimulating but also emotionally engaging, thanks to the deeply personal stakes for the protagonist, Dom Cobb. The film's exploration of themes such as reality, illusion, and the personal cost of survival adds depth and philosophical weight to the story.\n",
      "\n",
      "The performances, particularly by Leonardo DiCaprio, are another strong point. DiCaprio brings a sense of vulnerability and desperation to his character, making the audience empathize with his plight. The supporting cast, including Ellen Page, Joseph Gordon-Levitt, and Tom Hardy, also deliver strong performances.\n",
      "\n",
      "The film's visual effects and action sequences are spectacular, creating a dreamlike atmosphere that blurs the line between reality and illusion. The film's score, composed by Hans Zimmer, complements the visuals perfectly, enhancing the tension and emotional impact of the scenes.\n",
      "\n",
      "However, \"Inception\" is not without its weak points. The film's complex plot can be confusing for some viewers, requiring multiple viewings to fully understand. The film also relies heavily on exposition, with characters often explaining the rules of the dream world, which can slow down the pacing and disrupt the narrative flow. Furthermore, while the film delves into the subconscious mind, it doesn't fully explore the psychological aspects of the characters, missing an opportunity for deeper character development. Lastly, some viewers might find the film's ending ambiguous and unsatisfying. Despite these flaws, \"Inception\" remains a groundbreaking and thought-provoking film that pushes the boundaries of storytelling.\n",
      "Character Verdict: 1. Dom Cobb (Leonardo DiCaprio): Cobb is a highly skilled extractor with a deep understanding of the human subconscious. His strength lies in his intelligence, creativity, and determination. However, his guilt over his wife's death and his longing to return to his children are his major weaknesses. These emotional vulnerabilities often cloud his judgment and put his team at risk.\n",
      "\n",
      "2. Arthur (Joseph Gordon-Levitt): Arthur is Cobb's right-hand man and is extremely reliable, organized, and pragmatic. His strengths are his loyalty and his ability to think quickly in high-pressure situations. However, his weakness is his lack of imagination, which is highlighted when compared to Ariadne's creativity.\n",
      "\n",
      "3. Ariadne (Ellen Page): Ariadne is a brilliant architect who is recruited to design the dreamscapes. Her strengths are her intelligence, creativity, and curiosity. She is also the moral compass of the team. Her weakness, however, is her inexperience in the world of dream extraction, which sometimes leads to dangerous situations.\n",
      "\n",
      "4. Mal Cobb (Marion Cotillard): Mal is the projection of Cobb's guilt over his wife's death. Her strength is her power over Cobb, as she can manipulate his emotions and actions. However, her weakness is that she is not real but a manifestation of Cobb's subconscious, and her existence hinges on his guilt and inability to let go of the past.\n",
      "\n",
      "5. Robert Fischer (Cillian Murphy): Fischer is the mark from whom Cobb's team must plant an idea. His strength is his initial resistance to inception, demonstrating a strong subconscious. His weakness is his complicated relationship with his father, which Cobb's team exploits to successfully plant the idea.\n",
      "\n",
      "6. Eames (Tom Hardy): Eames is the forger of the team, able to shape-shift into other people in the dream world. His strength is his adaptability and quick wit. However, his weakness is his overconfidence, which can sometimes lead to underestimating the risks involved.\n",
      "\n",
      "7. Saito (Ken Watanabe): Saito is the wealthy businessman who hires Cobb's team. His strength is his influence and resources. His weakness is his obsession with achieving his corporate goals, which blinds him to the potential dangers and ethical implications of inception.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda, RunnableParallel\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "def analyze_movie(plot):\n",
    "    plot_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a movie critic.\"),\n",
    "        (\"human\", \"analyze the plot{plot}. what are the strong and weak points?\"),\n",
    "    ])\n",
    "    return plot_template.format_prompt(plot=plot)\n",
    "    \n",
    "\n",
    "def analyze_characters(characters):\n",
    "    character_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a movie critic.\"),\n",
    "        (\"human\", \"analyze the characters in the movie {character}. what are their strengths and weaknesses?\"),\n",
    "    ])\n",
    "    return character_template.format_prompt(character=characters)\n",
    "\n",
    "def combine_verdicts(plot_verdict, character_verdict):\n",
    "    return f\"Plot Verdict: {plot_verdict}\\nCharacter Verdict: {character_verdict}\"\n",
    "\n",
    "def main():\n",
    "    # Initialize the language model\n",
    "    llm = ChatOpenAI(model=\"gpt-4\", temperature=0.0)\n",
    "\n",
    "    # Define the prompt template\n",
    "    summarizer = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a movie critic \"),\n",
    "        (\"human\", \"provide a brief summary on the movie {movie_name}\"),\n",
    "    ])\n",
    "\n",
    "    # Create a chain for analyzing the movie plot\n",
    "    plot_chain = RunnableLambda(lambda x: analyze_movie(x)) | llm | StrOutputParser()\n",
    "    # Create a chain for analyzing the characters\n",
    "    character_chain = RunnableLambda(lambda x: analyze_characters(x)) | llm | StrOutputParser()\n",
    "    # Combine the two chains in parallel\n",
    "    parallel_chain = RunnableParallel(\n",
    "        branches={\n",
    "            \"plot\": plot_chain,\n",
    "            \"character\": character_chain\n",
    "        },\n",
    "    )\n",
    "    # Combine the verdicts\n",
    "    combine_chain = RunnableLambda(lambda x: combine_verdicts(x[\"branches\"][\"plot\"], x[\"branches\"][\"character\"]))\n",
    "    # Create the final chain\n",
    "    # final_chain = RunnableSequence(\n",
    "    #     summarizer,\n",
    "    #     llm,\n",
    "    #     StrOutputParser(),\n",
    "    #     parallel_chain,\n",
    "    #     # combine_chain\n",
    "    # )\n",
    "    final_chain = summarizer | llm | StrOutputParser() | parallel_chain | combine_chain\n",
    "    # Run the chain with a sample movie\n",
    "    result = final_chain.invoke({\"movie_name\": \"Inception\"})\n",
    "    print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Chaining\n",
    "project example user feedback analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Result: Dear Customer,\n",
      "\n",
      "We're sorry to hear about your negative experience. We always aim to deliver a great experience, and we are gutted when we don’t meet expectations. Thanks for taking the time to bring this to our attention. We will use the feedback to make us better and to ensure this doesn’t happen again. \n",
      "\n",
      "Best Regards,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda, RunnableSequence, RunnableBranch\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "def main():\n",
    "    # Initialize the language model\n",
    "    llm = ChatOpenAI(model=\"gpt-4\", temperature=0.0)\n",
    "\n",
    "    # Define the prompt template\n",
    "    classification = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful assistant in customer feedback.\"),\n",
    "        (\"human\", \"Classify the feedback: {feedback} into positive, negative, or neutral.\"),\n",
    "    ])\n",
    "    classification_chain = classification | llm | StrOutputParser()\n",
    "    positive_feedback = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful assistant in customer feedback.\"),\n",
    "        (\"human\", \"Provide a positive response to the feedback: {feedback}\"),\n",
    "    ])\n",
    "    negative_feedback = ChatPromptTemplate.from_messages([  \n",
    "        (\"system\", \"You are a helpful assistant in customer feedback.\"),\n",
    "        (\"human\", \"Provide a negative response to the feedback: {feedback}\"),\n",
    "    ])\n",
    "    neutral_feedback = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful assistant in customer feedback.\"),\n",
    "        (\"human\", \"Provide a neutral response to the feedback: {feedback}\"),\n",
    "    ])\n",
    "    escalate_feedback = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful assistant in customer feedback.\"),\n",
    "        (\"human\", \"Escalate the feedback: {feedback} to the appropriate team.\"),\n",
    "    ])\n",
    "    branches = RunnableBranch(\n",
    "        \n",
    "            (lambda x: \"positive\" in x, positive_feedback| llm | StrOutputParser()),\n",
    "            (lambda x:\"negative\" in x, negative_feedback | llm | StrOutputParser()),\n",
    "            (lambda x: \"neutral\" in x, neutral_feedback | llm | StrOutputParser()),\n",
    "        \n",
    "            escalate_feedback | llm | StrOutputParser()\n",
    "    )\n",
    "    chain = RunnableSequence(\n",
    "        classification_chain,\n",
    "        branches\n",
    "    )\n",
    "    result = chain.invoke({\"feedback\": \"Terrible service, I will never come back!\"})\n",
    "    print(f\"Classification Result: {result}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
