{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Chaining\n",
    "\n",
    "## 1. Extendend or sequential chaining\n",
    "chaining tasks one by one in a sequential line\n",
    "\n",
    "## 2. parallel chaining\n",
    "lets you run tasks without depending on other tasks \n",
    "\n",
    "## 3. conditional chaining\n",
    "lets you run a particular branch based on a condition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Turing Test is a method of inquiry in artificial intelligence (AI) for determining whether or not a computer is capable of human-like intelligence. Proposed by the British mathematician and computer scientist Alan Turing in 1950, the test involves a human evaluator who carries out natural language conversations with another human and a machine designed to generate human-like responses. The evaluator knows that one of the two partners in conversation is a machine, and all participants are separated from one another. If the evaluator cannot reliably tell the machine from the human, the machine is said to have passed the test. The test does not check the ability to give correct answers, it checks how closely the answer resembles typical human answers.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def main():\n",
    "    # Initialize the language model\n",
    "    llm = ChatOpenAI(model=\"gpt-4\", temperature=0.0)\n",
    "\n",
    "    # Define the prompt template\n",
    "    # prompt = PromptTemplate(\n",
    "    #     input_variables=[\"question\"],\n",
    "    #     template=\"Answer the question: {question}\",\n",
    "    # )\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful assistant in the {field}.\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ])\n",
    "\n",
    "    # Create the output parser\n",
    "    output_parser = StrOutputParser()\n",
    "\n",
    "    # Combine the components into a single chain\n",
    "    chain = prompt | llm | output_parser\n",
    "\n",
    "    # Run the chain with a sample question\n",
    "    result = chain.invoke({\"field\": \"computer science\", \"question\": \"What is the Turing test?\"})\n",
    "    \n",
    "    print(result)\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "# This script uses LangChain to create a simple question-answering chain with OpenAI's GPT-4 model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
