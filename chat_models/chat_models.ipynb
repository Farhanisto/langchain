{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAT PROMPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The capital of France is Paris.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 14, 'total_tokens': 21, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-BgUf8NKqD9LEcrKkJLMV9wGBz953i', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--6f401854-99f9-4ec4-867b-db8e3b69218d-0' usage_metadata={'input_tokens': 14, 'output_tokens': 7, 'total_tokens': 21, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai  import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "result = llm.invoke(\"What is the capital of France?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# passing chat history\n",
    "\n",
    "##Type of messsages\n",
    "\n",
    "### system messages: eg you are a marketing expert\n",
    "### human messages : This are human messages\n",
    "### AI messages: eg focus on social media engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create engaging social media posts on Instagram, focus on storytelling through high-quality visuals paired with concise, compelling captions. Use aesthetically pleasing images or videos to draw attention, and ensure your captions evoke emotion or curiosity, prompting users to interact. Incorporate relevant hashtags and encourage engagement by asking questions or including a call-to-action (CTA), such as inviting followers to share their thoughts in the comments. Consider using interactive elements like polls or quizzes in Instagram Stories to enhance engagement further.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "messages = [SystemMessage(\"you are an expert in social media content strategy\"),\n",
    "           HumanMessage(\"give a short tip to create engaging social media posts on instagram\")]\n",
    "\n",
    "result = llm.invoke(messages)\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALTERNATIVe LLMS\n",
    "\n",
    "# using anthropic or google gemini\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "messages = [SystemMessage('you are an expert in marketing'), HumanMessage('give a short tip on how to create engaging ads')]\n",
    "llm = ChatAnthropic(model=\"claude-3-opus-20240229\")\n",
    "result = llm.invoke(messages)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realtime conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "chat_history = []\n",
    "system_message = SystemMessage('you are a helpful assistant')\n",
    "chat_history.append(system_message)\n",
    "\n",
    "while True:\n",
    "    query = input(\"You:\")\n",
    "    if query.lower() == 'exit':\n",
    "        break\n",
    "    chat_history.append(HumanMessage(content=query))\n",
    "    result = llm.invoke(chat_history)\n",
    "    chat_history.append(AIMessage(content=result.content))\n",
    "    print(f\"AI:{result.content}\")\n",
    "\n",
    "print(\"Message History\")\n",
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAT HISTORY IN CLOUD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from google.cloud import firestore\n",
    "from langchain_google_firestore import FirestoreChatMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "PROJECT_ID = \"langchain-5eaaa\"\n",
    "SESSION_ID = \"sadjlksdjf\"\n",
    "COLLECTION_NAME = \"chat_history\"\n",
    "\n",
    "firestore_client = firestore.Client(project=PROJECT_ID)\n",
    "chat_history = FirestoreChatMessageHistory(session_id=SESSION_ID, collection=COLLECTION_NAME, client=firestore_client)\n",
    "print(\"chat history initialized\", chat_history.messages)\n",
    "model = ChatOpenAI(model= \"gpt-4o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
