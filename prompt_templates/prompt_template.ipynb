{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Friendly Reminder: Upcoming Project Deadline\n",
      "\n",
      "Hi Alice,\n",
      "\n",
      "I hope this email finds you well! I just wanted to touch base regarding our upcoming project deadline. As we discussed, the due date is approaching on [insert date], and I thought it might be helpful to check in and see how everything is progressing on your end.\n",
      "\n",
      "If there’s anything you need or if you’d like to brainstorm together, please feel free to reach out. I’m here to help and support in any way I can. Let’s make sure we’re all set to wrap things up smoothly and on time.\n",
      "\n",
      "Looking forward to your thoughts and any updates you might have. Thanks for all your hard work and dedication!\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def main():\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
    "    template = \"write a {tone} email to {recipient} about {topic}\"\n",
    "    prompt_template = ChatPromptTemplate.from_template(template)\n",
    "    prompt=prompt_template.invoke(\n",
    "        {\n",
    "            \"tone\": \"friendly\",\n",
    "            \"recipient\": \"Alice\",\n",
    "            \"topic\": \"the upcoming project deadline\",\n",
    "            \"due date\": \"next Friday\"\n",
    "        }\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    print(response.content)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "# This script uses LangChain to create a chat prompt template and invoke an LLM to generate a friendly email.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a standup comedian who tells jokes about AI.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me  3 jokes.', additional_kwargs={}, response_metadata={})]\n",
      "Sure, here are three AI-themed jokes for you:\n",
      "\n",
      "1. Why did the AI break up with its partner?\n",
      "   Because it couldn't handle all the emotional data—it preferred things binary!\n",
      "\n",
      "2. How do you make an AI laugh?\n",
      "   You tell it a joke in Python, but make sure to include a good punch(line) of code!\n",
      "\n",
      "3. Why did the AI go to therapy?\n",
      "   It had too many unresolved loops and couldn't stop overthinking!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "def main():\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a standup comedian who tells jokes about {topic}.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me  {number_jokes} jokes.\"},\n",
    "    ]\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_messages(messages=messages)\n",
    "    prompt = prompt_template.invoke(\n",
    "        {\n",
    "            \"topic\": \"AI\",\n",
    "            \"number_jokes\": 3\n",
    "        }\n",
    "    )\n",
    "    print(prompt)\n",
    "    response = llm.invoke(prompt)\n",
    "    print(response.content)\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "# This script uses LangChain to create a chat prompt template and invoke an LLM to generate jokes about a specified topic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
